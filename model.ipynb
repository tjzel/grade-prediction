{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "  \n",
    "# Fetching the dataset. \n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "\n",
    "categorical_columns = student_performance.variables[student_performance.variables['type'].isin(['Categorical', 'Binary'])]\n",
    "\n",
    "# Some of the features are categorical - we'll need to encode them later on, we extract the indices of columns already.\n",
    "indices = categorical_columns.index.tolist()\n",
    "indices = [index for index in indices if index < 30]\n",
    "   \n",
    "X = student_performance.data.features\n",
    "y = student_performance.data.targets\n",
    "\n",
    "# Extracting the targets\n",
    "G1_multiclass = y.iloc[:, 0]\n",
    "G2_multiclass = y.iloc[:, 1]\n",
    "G3_multiclass = y.iloc[:, 2]\n",
    "\n",
    "# Move G1 and G2 to features for later use.\n",
    "X_with_G1 = pd.concat([X, G1_multiclass], axis=1)\n",
    "X_with_G1_G2 = pd.concat([X_with_G1, G2_multiclass], axis=1)\n",
    "\n",
    "# Student's perfomance is in a 1-20 scale, we'll turn it into a binary classification problem - passing the class or failing it.\n",
    "threshold = 10\n",
    "G1 = np.where(G1_multiclass >= threshold, 1, 0)\n",
    "G2 = np.where(G2_multiclass >= threshold, 1, 0)\n",
    "G3 = np.where(G3_multiclass >= threshold, 1, 0)\n",
    "\n",
    "# Although we will use the same data for all three groups, we need to get the same splits for each group.\n",
    "G1_X_train, G1_X_test, G1_y_train, G1_y_test = train_test_split(X, G1, test_size=0.2, random_state=2137)\n",
    "G2_X_train, G2_X_test, G2_y_train, G2_y_test = train_test_split(X, G2, test_size=0.2, random_state=2137)\n",
    "G3_X_train, G3_X_test, G3_y_train, G3_y_test = train_test_split(X, G3, test_size=0.2, random_state=2137)\n",
    "G3_X_with_G1_G2_train, G3_X_with_G1_G2_test, G3_y_with_G1_G2_train, G3_y_with_G1_G2_test = train_test_split(X_with_G1_G2, G3, test_size=0.2, random_state=2137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and AdaBoost model preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Defining the preprocessing steps. We will use them for both models.\n",
    "preprocessing_steps = [\n",
    "  # We need to convert the categorical features.\n",
    "  ('encoder', ColumnTransformer(transformers=[('encoder', OrdinalEncoder(), indices)], remainder='passthrough')),\n",
    "  # Normalizing the data.\n",
    "  ('scaler', StandardScaler()),\n",
    "]\n",
    "\n",
    "qualification_steps = [\n",
    "    ('model', AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=2137, algorithm='SAMME')),\n",
    "]\n",
    "\n",
    "# Creating the pipeline for AdaBoostClassifier.\n",
    "pipeline = Pipeline(steps=preprocessing_steps + qualification_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best hyperparameters for AdaBoost model with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "Best Parameters: {'model__n_estimators': 24, 'model__learning_rate': 0.6500000000000001, 'model__estimator__min_samples_leaf': 7, 'model__estimator__max_depth': 2}\n",
      "Best Score: 0.8343726661687827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': np.arange(4, 128, 4),\n",
    "    'model__learning_rate': np.arange(0.05, 1.0, 0.05),\n",
    "    'model__estimator__max_depth': np.arange(1, 10, 1),\n",
    "    'model__estimator__min_samples_leaf': np.arange(1, 10, 1),\n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object with the pipeline.\n",
    "grid_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=1024, scoring='accuracy', n_jobs=-1, verbose=1, random_state=2137) \n",
    "\n",
    "# Fit the data to the GridSearchCV object.\n",
    "bestModel = grid_search.fit(G1_X_train, G1_y_train).best_estimator_\n",
    "\n",
    "# Get the best parameters and the best score.\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Make the predictions.\n",
    "G1_pred = bestModel.predict(G1_X_test)\n",
    "G2_pred = bestModel.predict(G2_X_test)\n",
    "G3_pred = bestModel.predict(G3_X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosts model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on G1: 0.8076923076923077\n",
      "Accuracy on G2: 0.7846153846153846\n",
      "Accuracy on G3: 0.8307692307692308\n",
      "Precision on G1: 0.8365384615384616\n",
      "Precision on G2: 0.8269230769230769\n",
      "Precision on G3: 0.9038461538461539\n",
      "Recall on G1: 0.9157894736842105\n",
      "Recall on G2: 0.8958333333333334\n",
      "Recall on G3: 0.8867924528301887\n",
      "F1 Score on G1: 0.8743718592964824\n",
      "F1 Score on G2: 0.86\n",
      "F1 Score on G3: 0.8952380952380953\n",
      "Confusion Matrix on G1:\n",
      " [[18 17]\n",
      " [ 8 87]]\n",
      "Confusion Matrix on G2:\n",
      " [[16 18]\n",
      " [10 86]]\n",
      "Confusion Matrix on G3:\n",
      " [[14 10]\n",
      " [12 94]]\n",
      "Classification Report on G1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.69      0.51      0.59        35\n",
      "        Pass       0.84      0.92      0.87        95\n",
      "\n",
      "    accuracy                           0.81       130\n",
      "   macro avg       0.76      0.72      0.73       130\n",
      "weighted avg       0.80      0.81      0.80       130\n",
      "\n",
      "Classification Report on G2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.62      0.47      0.53        34\n",
      "        Pass       0.83      0.90      0.86        96\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.72      0.68      0.70       130\n",
      "weighted avg       0.77      0.78      0.77       130\n",
      "\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.54      0.58      0.56        24\n",
      "        Pass       0.90      0.89      0.90       106\n",
      "\n",
      "    accuracy                           0.83       130\n",
      "   macro avg       0.72      0.74      0.73       130\n",
      "weighted avg       0.84      0.83      0.83       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy_G1 = accuracy_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "accuracy_G2 = accuracy_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G1:\", accuracy_G1)\n",
    "print(\"Accuracy on G2:\", accuracy_G2)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G1 = precision_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "precision_G2 = precision_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "precision_G3 = precision_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Precision on G1:\", precision_G1)\n",
    "print(\"Precision on G2:\", precision_G2)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G1 = recall_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "recall_G2 = recall_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "recall_G3 = recall_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Recall on G1:\", recall_G1)\n",
    "print(\"Recall on G2:\", recall_G2)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G1 = f1_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "f1_G2 = f1_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "f1_G3 = f1_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G1:\", f1_G1)\n",
    "print(\"F1 Score on G2:\", f1_G2)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G1 = confusion_matrix(y_true=G1_y_test, y_pred=G1_pred)\n",
    "conf_matrix_G2 = confusion_matrix(y_true=G2_y_test, y_pred=G2_pred)\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G1:\\n\", conf_matrix_G1)\n",
    "print(\"Confusion Matrix on G2:\\n\", conf_matrix_G2)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G1 = classification_report(y_true=G1_y_test, y_pred=G1_pred, target_names=target_names)\n",
    "classification_report_G2 = classification_report(y_true=G2_y_test, y_pred=G2_pred, target_names=target_names)\n",
    "classification_report_G3 = classification_report(y_true=G3_y_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G1:\\n\", classification_report_G1)\n",
    "print(\"Classification Report on G2:\\n\", classification_report_G2)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./G1/tuner0.json\n",
      "{'units': 64, 'hidden_layers': 6, 'activation': 'relu', 'dropout': 0.2, 'size_factor': 1.5}\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Accuracy on train G1: 0.8076923076923077\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 46 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 722us/step\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras import models, layers, callbacks\n",
    "\n",
    "# We'll use keras_tuner to search for the best hyperparameters.\n",
    "def build_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Input((30,)),\n",
    "    ])\n",
    "\n",
    "    # We want to find the best starting size for the hidden layers.\n",
    "    units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    current_units = units\n",
    "\n",
    "    # We want to find the best number of hidden layers.\n",
    "    for i in range(1, hp.Int('hidden_layers', min_value=2, max_value=6, step=1)):\n",
    "\n",
    "        # We want to find the best activation function for everu hidden layer.\n",
    "        model.add(layers.Dense(units=current_units, activation=hp.Choice('activation', ['relu', 'sigmoid', 'softmax'])))\n",
    "        # Batch normalization is a good idea.\n",
    "        model.add(layers.BatchNormalization())\n",
    "        # We want to find the best dropout rate for every hidden layer.\n",
    "        model.add(layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        # We want to find the best ratio of input to output units for every hidden layer.\n",
    "        current_units = int(current_units // hp.Float('size_factor', min_value=1.0, max_value=4.0, step=0.5))\n",
    "\n",
    "    # Since the problem is binary, we want to use a sigmoid activation function.\n",
    "    model.add(layers.Dense(1, activation='sigmoid',))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='accuracy', patience=8) \n",
    "\n",
    "# We need to get the data preprocessed before we can use it for training.\n",
    "transformed_G1_X_train = Pipeline(steps=preprocessing_steps).fit_transform(G1_X_train, G1_y_train)\n",
    "transformed_G1_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G1_X_test, G1_y_test)\n",
    "\n",
    "transformed_G2_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G2_X_test, G2_y_test)\n",
    "transformed_G3_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_test, G3_y_test)\n",
    "\n",
    "# Since there's numerous combinations of hyperparameters, we'll use a random search to find the best combination.\n",
    "tuner = RandomSearch(hypermodel=build_model, objective='val_accuracy', max_trials=128, seed=2137, project_name='G1')\n",
    "tuner.search(transformed_G1_X_train, G1_y_train, epochs=128, callbacks=[early_stopping], validation_data=(transformed_G1_X_test, G1_y_test), verbose=1)\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "G1_pred_train = model.predict(transformed_G1_X_train)\n",
    "G1_pred_train = np.where(G1_pred_train >= 0.5, 1, 0)\n",
    "\n",
    "accuracy_G3 = accuracy_score(y_true=G1_y_train, y_pred=G1_pred_train)\n",
    "print(\"Accuracy on train G1:\", accuracy_G1)\n",
    "\n",
    "G1_pred = model.predict(transformed_G1_X_test)\n",
    "G1_pred = np.where(G1_pred >= 0.5, 1, 0)\n",
    "\n",
    "G2_pred = model.predict(transformed_G2_X_test)\n",
    "G2_pred = np.where(G2_pred >= 0.5, 1, 0)\n",
    "\n",
    "G3_pred = model.predict(transformed_G3_X_test)\n",
    "G3_pred = np.where(G3_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,730</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">168</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,204</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">522</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">228</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m1,984\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │         \u001b[38;5;34m2,730\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │           \u001b[38;5;34m168\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m42\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │         \u001b[38;5;34m1,204\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │           \u001b[38;5;34m112\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │           \u001b[38;5;34m522\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │            \u001b[38;5;34m72\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │           \u001b[38;5;34m228\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │            \u001b[38;5;34m48\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m13\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,337</span> (28.66 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,337\u001b[0m (28.66 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,009</span> (27.38 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m7,009\u001b[0m (27.38 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328</span> (1.28 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m328\u001b[0m (1.28 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Accuracy on G1: 0.8538461538461538\n",
      "Accuracy on G2: 0.8153846153846154\n",
      "Accuracy on G3: 0.8461538461538461\n",
      "Precision on G1: 0.88\n",
      "Precision on G2: 0.86\n",
      "Precision on G3: 0.93\n",
      "Recall on G1: 0.9263157894736842\n",
      "Recall on G2: 0.8958333333333334\n",
      "Recall on G3: 0.8773584905660378\n",
      "F1 Score on G1: 0.9025641025641026\n",
      "F1 Score on G2: 0.8775510204081632\n",
      "F1 Score on G3: 0.9029126213592233\n",
      "Confusion Matrix on G1:\n",
      " [[23 12]\n",
      " [ 7 88]]\n",
      "Confusion Matrix on G2:\n",
      " [[20 14]\n",
      " [10 86]]\n",
      "Confusion Matrix on G3:\n",
      " [[17  7]\n",
      " [13 93]]\n",
      "Classification Report on G1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.77      0.66      0.71        35\n",
      "        Pass       0.88      0.93      0.90        95\n",
      "\n",
      "    accuracy                           0.85       130\n",
      "   macro avg       0.82      0.79      0.81       130\n",
      "weighted avg       0.85      0.85      0.85       130\n",
      "\n",
      "Classification Report on G2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.67      0.59      0.62        34\n",
      "        Pass       0.86      0.90      0.88        96\n",
      "\n",
      "    accuracy                           0.82       130\n",
      "   macro avg       0.76      0.74      0.75       130\n",
      "weighted avg       0.81      0.82      0.81       130\n",
      "\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.57      0.71      0.63        24\n",
      "        Pass       0.93      0.88      0.90       106\n",
      "\n",
      "    accuracy                           0.85       130\n",
      "   macro avg       0.75      0.79      0.77       130\n",
      "weighted avg       0.86      0.85      0.85       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "accuracy_G1 = accuracy_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "accuracy_G2 = accuracy_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G1:\", accuracy_G1)\n",
    "print(\"Accuracy on G2:\", accuracy_G2)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G1 = precision_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "precision_G2 = precision_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "precision_G3 = precision_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Precision on G1:\", precision_G1)\n",
    "print(\"Precision on G2:\", precision_G2)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G1 = recall_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "recall_G2 = recall_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "recall_G3 = recall_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Recall on G1:\", recall_G1)\n",
    "print(\"Recall on G2:\", recall_G2)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G1 = f1_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "f1_G2 = f1_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "f1_G3 = f1_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G1:\", f1_G1)\n",
    "print(\"F1 Score on G2:\", f1_G2)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G1 = confusion_matrix(y_true=G1_y_test, y_pred=G1_pred)\n",
    "conf_matrix_G2 = confusion_matrix(y_true=G2_y_test, y_pred=G2_pred)\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G1:\\n\", conf_matrix_G1)\n",
    "print(\"Confusion Matrix on G2:\\n\", conf_matrix_G2)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G1 = classification_report(y_true=G1_y_test, y_pred=G1_pred, target_names=target_names)\n",
    "classification_report_G2 = classification_report(y_true=G2_y_test, y_pred=G2_pred, target_names=target_names)\n",
    "classification_report_G3 = classification_report(y_true=G3_y_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G1:\\n\", classification_report_G1)\n",
    "print(\"Classification Report on G2:\\n\", classification_report_G2)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the neural network model isn't a significant improvement over the previous model. My hypothesis here is that the data we are providing isn't containing all the important features. Let's now use the data that also has G1 and G2 as features.\n",
    "\n",
    "## AdaBoost model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "Best Parameters: {'model__n_estimators': 48, 'model__learning_rate': 0.15000000000000002, 'model__estimator__min_samples_leaf': 2, 'model__estimator__max_depth': 8}\n",
      "Best Score: 0.9557505601194922\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'model__n_estimators': np.arange(4, 128, 4),\n",
    "    'model__learning_rate': np.arange(0.05, 1.0, 0.05),\n",
    "    'model__estimator__max_depth': np.arange(1, 10, 1),\n",
    "    'model__estimator__min_samples_leaf': np.arange(1, 10, 1),\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=1024, scoring='accuracy', n_jobs=-1, verbose=1, random_state=2137) \n",
    "\n",
    "bestModel = grid_search.fit(G3_X_with_G1_G2_train, G3_y_with_G1_G2_train).best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "G3_pred = bestModel.predict(G3_X_with_G1_G2_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on G3: 0.8923076923076924\n",
      "Precision on G3: 0.9181818181818182\n",
      "Recall on G3: 0.9528301886792453\n",
      "F1 Score on G3: 0.9351851851851852\n",
      "Confusion Matrix on G3:\n",
      " [[ 15   9]\n",
      " [  5 101]]\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.75      0.62      0.68        24\n",
      "        Pass       0.92      0.95      0.94       106\n",
      "\n",
      "    accuracy                           0.89       130\n",
      "   macro avg       0.83      0.79      0.81       130\n",
      "weighted avg       0.89      0.89      0.89       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_G3 = accuracy_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G3 = precision_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G3 = recall_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G3 = f1_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G3 = classification_report(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model hasn't improved much. Let's see the neural network.\n",
    "\n",
    "## Neural network on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./G3_with_G1_G2/tuner0.json\n",
      "Model summary:\n",
      "Results summary\n",
      "Results in ./G3_with_G1_G2\n",
      "Showing 1 best trials\n",
      "Objective(name=\"val_accuracy\", direction=\"max\")\n",
      "\n",
      "Trial 004 summary\n",
      "Hyperparameters:\n",
      "units: 128\n",
      "hidden_layers: 4\n",
      "activation: relu\n",
      "dropout: 0.1\n",
      "size_factor: 4.0\n",
      "Score: 0.9384615421295166\n",
      "None\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "Accuracy on train G3: 0.9980732177263969\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras import models, layers, callbacks\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Input((32,)),\n",
    "    ])\n",
    "\n",
    "    units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    current_units = units\n",
    "\n",
    "    for i in range(1, hp.Int('hidden_layers', min_value=2, max_value=6, step=1)):\n",
    "\n",
    "        model.add(layers.Dense(units=current_units, activation=hp.Choice('activation', ['relu', 'sigmoid', 'softmax'])))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        current_units = int(current_units // hp.Float('size_factor', min_value=1.0, max_value=4.0, step=0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid',))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='accuracy', patience=8) \n",
    "\n",
    "transformed_G3_X_with_G1_G2_train = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_with_G1_G2_train, G3_y_with_G1_G2_train)\n",
    "transformed_G3_X_with_G1_G2_test = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_with_G1_G2_test, G3_y_with_G1_G2_test)\n",
    "\n",
    "tuner = RandomSearch(hypermodel=build_model, objective='val_accuracy', max_trials=128, seed=2137, project_name='G3_with_G1_G2')\n",
    "tuner.search(transformed_G3_X_with_G1_G2_train, G3_y_with_G1_G2_train, epochs=128, callbacks=[early_stopping], validation_data=(transformed_G3_X_with_G1_G2_test, G3_y_with_G1_G2_test), verbose=1)\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "\n",
    "print(\"Model summary:\")\n",
    "print(tuner.results_summary(1))\n",
    "\n",
    "G3_pred_train = model.predict(transformed_G3_X_with_G1_G2_train)\n",
    "G3_pred_train = np.where(G3_pred_train >= 0.5, 1, 0)\n",
    "\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_with_G1_G2_train, y_pred=G3_pred_train)\n",
    "print(\"Accuracy on train G3:\", accuracy_G3)\n",
    "\n",
    "G3_pred = model.predict(transformed_G3_X_with_G1_G2_test)\n",
    "G3_pred = np.where(G3_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,128</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m4,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m4,128\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │            \u001b[38;5;34m32\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,297</span> (36.32 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,297\u001b[0m (36.32 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,961</span> (35.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,961\u001b[0m (35.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">336</span> (1.31 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m336\u001b[0m (1.31 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Accuracy on G3: 0.9384615384615385\n",
      "Precision on G3: 0.9537037037037037\n",
      "Recall on G3: 0.9716981132075472\n",
      "F1 Score on G3: 0.9626168224299065\n",
      "Confusion Matrix on G3:\n",
      " [[ 19   5]\n",
      " [  3 103]]\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.86      0.79      0.83        24\n",
      "        Pass       0.95      0.97      0.96       106\n",
      "\n",
      "    accuracy                           0.94       130\n",
      "   macro avg       0.91      0.88      0.89       130\n",
      "weighted avg       0.94      0.94      0.94       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G3 = precision_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G3 = recall_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G3 = f1_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G3 = classification_report(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
