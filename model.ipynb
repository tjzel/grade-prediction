{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "  \n",
    "# Fetching the dataset. \n",
    "student_performance = fetch_ucirepo(id=320) \n",
    "\n",
    "categorical_columns = student_performance.variables[student_performance.variables['type'].isin(['Categorical', 'Binary'])]\n",
    "\n",
    "# Some of the features are categorical - we'll need to encode them later on, we extract the indices of columns already.\n",
    "indices = categorical_columns.index.tolist()\n",
    "indices = [index for index in indices if index < 30]\n",
    "   \n",
    "X = student_performance.data.features\n",
    "y = student_performance.data.targets\n",
    "\n",
    "# Extracting the targets\n",
    "G1_multiclass = y.iloc[:, 0]\n",
    "G2_multiclass = y.iloc[:, 1]\n",
    "G3_multiclass = y.iloc[:, 2]\n",
    "\n",
    "# Move G1 and G2 to features for later use.\n",
    "X_with_G1 = pd.concat([X, G1_multiclass], axis=1)\n",
    "X_with_G1_G2 = pd.concat([X_with_G1, G2_multiclass], axis=1)\n",
    "\n",
    "# Student's perfomance is in a 1-20 scale, we'll turn it into a binary classification problem - passing the class or failing it.\n",
    "threshold = 10\n",
    "G1 = np.where(G1_multiclass >= threshold, 1, 0)\n",
    "G2 = np.where(G2_multiclass >= threshold, 1, 0)\n",
    "G3 = np.where(G3_multiclass >= threshold, 1, 0)\n",
    "\n",
    "# Although we will use the same data for all three groups, we need to get the same splits for each group.\n",
    "G1_X_train, G1_X_test, G1_y_train, G1_y_test = train_test_split(X, G1, test_size=0.2, random_state=2137)\n",
    "G2_X_train, G2_X_test, G2_y_train, G2_y_test = train_test_split(X, G2, test_size=0.2, random_state=2137)\n",
    "G3_X_train, G3_X_test, G3_y_train, G3_y_test = train_test_split(X, G3, test_size=0.2, random_state=2137)\n",
    "G3_X_with_G1_G2_train, G3_X_with_G1_G2_test, G3_y_with_G1_G2_train, G3_y_with_G1_G2_test = train_test_split(X_with_G1_G2, G3, test_size=0.2, random_state=2137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing and AdaBoost model preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# Defining the preprocessing steps. We will use them for both models.\n",
    "preprocessing_steps = [\n",
    "  # We need to convert the categorical features.\n",
    "  ('encoder', ColumnTransformer(transformers=[('encoder', OrdinalEncoder(), indices)], remainder='passthrough')),\n",
    "  # Normalizing the data.\n",
    "  ('scaler', StandardScaler()),\n",
    "]\n",
    "\n",
    "qualification_steps = [\n",
    "    ('model', AdaBoostClassifier(estimator=DecisionTreeClassifier(), random_state=2137, algorithm='SAMME')),\n",
    "]\n",
    "\n",
    "# Creating the pipeline for AdaBoostClassifier.\n",
    "pipeline = Pipeline(steps=preprocessing_steps + qualification_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the best hyperparameters for AdaBoost model with RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "Best Parameters: {'model__n_estimators': 88, 'model__learning_rate': 0.6000000000000001, 'model__estimator__min_samples_leaf': 4, 'model__estimator__max_depth': 1}\n",
      "Best Score: 0.8362770724421209\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'model__n_estimators': np.arange(4, 128, 4),\n",
    "    'model__learning_rate': np.arange(0.05, 1.0, 0.05),\n",
    "    'model__estimator__max_depth': np.arange(1, 10, 1),\n",
    "    'model__estimator__min_samples_leaf': np.arange(1, 10, 1),\n",
    "}\n",
    "\n",
    "# Create a RandomizedSearchCV object with the pipeline.\n",
    "grid_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=1024, scoring='accuracy', n_jobs=-1, verbose=1, random_state=2137) \n",
    "\n",
    "# Fit the data to the GridSearchCV object.\n",
    "bestModel = grid_search.fit(G1_X_train, G1_y_train).best_estimator_\n",
    "\n",
    "# Get the best parameters and the best score.\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Make the predictions.\n",
    "G1_pred = bestModel.predict(G1_X_test)\n",
    "G2_pred = bestModel.predict(G2_X_test)\n",
    "G3_pred = bestModel.predict(G3_X_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoosts model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on G1: 0.8076923076923077\n",
      "Accuracy on G2: 0.7846153846153846\n",
      "Accuracy on G3: 0.8307692307692308\n",
      "Precision on G1: 0.8301886792452831\n",
      "Precision on G2: 0.8207547169811321\n",
      "Precision on G3: 0.8962264150943396\n",
      "Recall on G1: 0.9263157894736842\n",
      "Recall on G2: 0.90625\n",
      "Recall on G3: 0.8962264150943396\n",
      "F1 Score on G1: 0.8756218905472637\n",
      "F1 Score on G2: 0.8613861386138614\n",
      "F1 Score on G3: 0.8962264150943396\n",
      "Confusion Matrix on G1:\n",
      " [[17 18]\n",
      " [ 7 88]]\n",
      "Confusion Matrix on G2:\n",
      " [[15 19]\n",
      " [ 9 87]]\n",
      "Confusion Matrix on G3:\n",
      " [[13 11]\n",
      " [11 95]]\n",
      "Classification Report on G1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.71      0.49      0.58        35\n",
      "        Pass       0.83      0.93      0.88        95\n",
      "\n",
      "    accuracy                           0.81       130\n",
      "   macro avg       0.77      0.71      0.73       130\n",
      "weighted avg       0.80      0.81      0.80       130\n",
      "\n",
      "Classification Report on G2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.62      0.44      0.52        34\n",
      "        Pass       0.82      0.91      0.86        96\n",
      "\n",
      "    accuracy                           0.78       130\n",
      "   macro avg       0.72      0.67      0.69       130\n",
      "weighted avg       0.77      0.78      0.77       130\n",
      "\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.54      0.54      0.54        24\n",
      "        Pass       0.90      0.90      0.90       106\n",
      "\n",
      "    accuracy                           0.83       130\n",
      "   macro avg       0.72      0.72      0.72       130\n",
      "weighted avg       0.83      0.83      0.83       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy_G1 = accuracy_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "accuracy_G2 = accuracy_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G1:\", accuracy_G1)\n",
    "print(\"Accuracy on G2:\", accuracy_G2)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G1 = precision_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "precision_G2 = precision_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "precision_G3 = precision_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Precision on G1:\", precision_G1)\n",
    "print(\"Precision on G2:\", precision_G2)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G1 = recall_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "recall_G2 = recall_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "recall_G3 = recall_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Recall on G1:\", recall_G1)\n",
    "print(\"Recall on G2:\", recall_G2)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G1 = f1_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "f1_G2 = f1_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "f1_G3 = f1_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G1:\", f1_G1)\n",
    "print(\"F1 Score on G2:\", f1_G2)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G1 = confusion_matrix(y_true=G1_y_test, y_pred=G1_pred)\n",
    "conf_matrix_G2 = confusion_matrix(y_true=G2_y_test, y_pred=G2_pred)\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G1:\\n\", conf_matrix_G1)\n",
    "print(\"Confusion Matrix on G2:\\n\", conf_matrix_G2)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G1 = classification_report(y_true=G1_y_test, y_pred=G1_pred, target_names=target_names)\n",
    "classification_report_G2 = classification_report(y_true=G2_y_test, y_pred=G2_pred, target_names=target_names)\n",
    "classification_report_G3 = classification_report(y_true=G3_y_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G1:\\n\", classification_report_G1)\n",
    "print(\"Classification Report on G2:\\n\", classification_report_G2)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network approach\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_accuracy So Far: None\n",
      "Total elapsed time: 00h 00m 00s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "32                |96                |units\n",
      "6                 |4                 |hidden_layers\n",
      "softmax           |sigmoid           |activation\n",
      "0.1               |0.2               |dropout\n",
      "3                 |4                 |size_factor\n",
      "\n",
      "Epoch 1/128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n",
      "    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n",
      "    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n",
      "    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n",
      "    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n",
      "    return model.fit(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n",
      "    raise ValueError(\n",
      "ValueError: Exception encountered when calling Sequential.call().\n",
      "\n",
      "\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 30, but received input with shape (None, 56)\u001b[0m\n",
      "\n",
      "Arguments received by Sequential.call():\n",
      "  • inputs=tf.Tensor(shape=(None, 56), dtype=float32)\n",
      "  • training=True\n",
      "  • mask=None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 30, but received input with shape (None, 56)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 56), dtype=float32)\n  • training=True\n  • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Since there's numerous combinations of hyperparameters, we'll use a random search to find the best combination.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(hypermodel\u001b[38;5;241m=\u001b[39mbuild_model, objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, max_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2137\u001b[39m, project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 44\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_G1_X_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG1_y_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformed_G1_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG1_y_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(tuner\u001b[38;5;241m.\u001b[39mget_best_hyperparameters()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues)\n",
      "File \u001b[0;32m~/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:235\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_run_and_update_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m--> 235\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_trial_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m~/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py:339\u001b[0m, in \u001b[0;36mBaseTuner.on_trial_end\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_trial_end\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial):\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Called at the end of a trial.\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03m        trial: A `Trial` instance.\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 339\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moracle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:108\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m     LOCKS[oracle]\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    107\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m thread_name\n\u001b[0;32m--> 108\u001b[0m ret_val \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m need_acquire:\n\u001b[1;32m    110\u001b[0m     THREADS[oracle] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:588\u001b[0m, in \u001b[0;36mOracle.end_trial\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry(trial):\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend_order\u001b[38;5;241m.\u001b[39mappend(trial\u001b[38;5;241m.\u001b[39mtrial_id)\n\u001b[0;32m--> 588\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_consecutive_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_trial(trial)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[0;32m~/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/oracle.py:545\u001b[0m, in \u001b[0;36mOracle._check_consecutive_failures\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    543\u001b[0m     consecutive_failures \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m consecutive_failures \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials:\n\u001b[0;32m--> 545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    546\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of consecutive failures exceeded the limit \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mof \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_consecutive_failed_trials\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    548\u001b[0m         \u001b[38;5;241m+\u001b[39m (trial\u001b[38;5;241m.\u001b[39mmessage \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    549\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Number of consecutive failures exceeded the limit of 3.\nTraceback (most recent call last):\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 274, in _try_run_and_update_trial\n    self._run_and_update_trial(trial, *fit_args, **fit_kwargs)\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/base_tuner.py\", line 239, in _run_and_update_trial\n    results = self.run_trial(trial, *fit_args, **fit_kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 314, in run_trial\n    obj_value = self._build_and_fit_model(trial, *args, **copied_kwargs)\n                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/tuner.py\", line 233, in _build_and_fit_model\n    results = self.hypermodel.fit(hp, model, *args, **kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras_tuner/src/engine/hypermodel.py\", line 149, in fit\n    return model.fit(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 122, in error_handler\n    raise e.with_traceback(filtered_tb) from None\n  File \"/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/layers/input_spec.py\", line 227, in assert_input_compatibility\n    raise ValueError(\nValueError: Exception encountered when calling Sequential.call().\n\n\u001b[1mInput 0 of layer \"dense\" is incompatible with the layer: expected axis -1 of input shape to have value 30, but received input with shape (None, 56)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(None, 56), dtype=float32)\n  • training=True\n  • mask=None\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras import models, layers, callbacks\n",
    "\n",
    "# We'll use keras_tuner to search for the best hyperparameters.\n",
    "def build_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Input((30,)),\n",
    "    ])\n",
    "\n",
    "    # We want to find the best starting size for the hidden layers.\n",
    "    units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    current_units = units\n",
    "\n",
    "    # We want to find the best number of hidden layers.\n",
    "    for i in range(1, hp.Int('hidden_layers', min_value=2, max_value=6, step=1)):\n",
    "\n",
    "        # We want to find the best activation function for everu hidden layer.\n",
    "        model.add(layers.Dense(units=current_units, activation=hp.Choice('activation', ['relu', 'sigmoid', 'softmax'])))\n",
    "        # Batch normalization is a good idea.\n",
    "        model.add(layers.BatchNormalization())\n",
    "        # We want to find the best dropout rate for every hidden layer.\n",
    "        model.add(layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        # We want to find the best ratio of input to output units for every hidden layer.\n",
    "        current_units = int(current_units // hp.Float('size_factor', min_value=1.0, max_value=4.0, step=0.5))\n",
    "\n",
    "    # Since the problem is binary, we want to use a sigmoid activation function.\n",
    "    model.add(layers.Dense(1, activation='sigmoid',))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='accuracy', patience=8) \n",
    "\n",
    "# We need to get the data preprocessed before we can use it for training.\n",
    "transformed_G1_X_train = Pipeline(steps=preprocessing_steps).fit_transform(G1_X_train, G1_y_train)\n",
    "transformed_G1_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G1_X_test, G1_y_test)\n",
    "\n",
    "transformed_G2_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G2_X_test, G2_y_test)\n",
    "transformed_G3_X_test = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_test, G3_y_test)\n",
    "\n",
    "# Since there's numerous combinations of hyperparameters, we'll use a random search to find the best combination.\n",
    "tuner = RandomSearch(hypermodel=build_model, objective='val_accuracy', max_trials=128, seed=2137, project_name='G1')\n",
    "tuner.search(transformed_G1_X_train, G1_y_train, epochs=128, callbacks=[early_stopping], validation_data=(transformed_G1_X_test, G1_y_test), verbose=1)\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "G1_pred = model.predict(transformed_G1_X_test)\n",
    "G1_pred = np.where(G1_pred >= 0.5, 1, 0)\n",
    "\n",
    "G2_pred = model.predict(transformed_G2_X_test)\n",
    "G2_pred = np.where(G2_pred >= 0.5, 1, 0)\n",
    "\n",
    "G3_pred = model.predict(transformed_G3_X_test)\n",
    "G3_pred = np.where(G3_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural network metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,965</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">340</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">85</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,816</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,109</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">148</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m3,968\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │        \u001b[38;5;34m10,965\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │           \u001b[38;5;34m340\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m85\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │         \u001b[38;5;34m4,816\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │           \u001b[38;5;34m224\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │         \u001b[38;5;34m2,109\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │           \u001b[38;5;34m148\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │           \u001b[38;5;34m912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │            \u001b[38;5;34m96\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m25\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,115</span> (94.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,115\u001b[0m (94.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,455</span> (91.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m23,455\u001b[0m (91.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660</span> (2.58 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m660\u001b[0m (2.58 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Accuracy on G1: 0.8307692307692308\n",
      "Accuracy on G2: 0.7923076923076923\n",
      "Accuracy on G3: 0.8538461538461538\n",
      "Precision on G1: 0.8411214953271028\n",
      "Precision on G2: 0.822429906542056\n",
      "Precision on G3: 0.9065420560747663\n",
      "Recall on G1: 0.9473684210526315\n",
      "Recall on G2: 0.9166666666666666\n",
      "Recall on G3: 0.9150943396226415\n",
      "F1 Score on G1: 0.8910891089108911\n",
      "F1 Score on G2: 0.8669950738916257\n",
      "F1 Score on G3: 0.9107981220657277\n",
      "Confusion Matrix on G1:\n",
      " [[18 17]\n",
      " [ 5 90]]\n",
      "Confusion Matrix on G2:\n",
      " [[15 19]\n",
      " [ 8 88]]\n",
      "Confusion Matrix on G3:\n",
      " [[14 10]\n",
      " [ 9 97]]\n",
      "Classification Report on G1:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.78      0.51      0.62        35\n",
      "        Pass       0.84      0.95      0.89        95\n",
      "\n",
      "    accuracy                           0.83       130\n",
      "   macro avg       0.81      0.73      0.76       130\n",
      "weighted avg       0.83      0.83      0.82       130\n",
      "\n",
      "Classification Report on G2:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.65      0.44      0.53        34\n",
      "        Pass       0.82      0.92      0.87        96\n",
      "\n",
      "    accuracy                           0.79       130\n",
      "   macro avg       0.74      0.68      0.70       130\n",
      "weighted avg       0.78      0.79      0.78       130\n",
      "\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.61      0.58      0.60        24\n",
      "        Pass       0.91      0.92      0.91       106\n",
      "\n",
      "    accuracy                           0.85       130\n",
      "   macro avg       0.76      0.75      0.75       130\n",
      "weighted avg       0.85      0.85      0.85       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "accuracy_G1 = accuracy_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "accuracy_G2 = accuracy_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G1:\", accuracy_G1)\n",
    "print(\"Accuracy on G2:\", accuracy_G2)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G1 = precision_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "precision_G2 = precision_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "precision_G3 = precision_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Precision on G1:\", precision_G1)\n",
    "print(\"Precision on G2:\", precision_G2)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G1 = recall_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "recall_G2 = recall_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "recall_G3 = recall_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Recall on G1:\", recall_G1)\n",
    "print(\"Recall on G2:\", recall_G2)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G1 = f1_score(y_true=G1_y_test, y_pred=G1_pred)\n",
    "f1_G2 = f1_score(y_true=G2_y_test, y_pred=G2_pred)\n",
    "f1_G3 = f1_score(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G1:\", f1_G1)\n",
    "print(\"F1 Score on G2:\", f1_G2)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G1 = confusion_matrix(y_true=G1_y_test, y_pred=G1_pred)\n",
    "conf_matrix_G2 = confusion_matrix(y_true=G2_y_test, y_pred=G2_pred)\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G1:\\n\", conf_matrix_G1)\n",
    "print(\"Confusion Matrix on G2:\\n\", conf_matrix_G2)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G1 = classification_report(y_true=G1_y_test, y_pred=G1_pred, target_names=target_names)\n",
    "classification_report_G2 = classification_report(y_true=G2_y_test, y_pred=G2_pred, target_names=target_names)\n",
    "classification_report_G3 = classification_report(y_true=G3_y_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G1:\\n\", classification_report_G1)\n",
    "print(\"Classification Report on G2:\\n\", classification_report_G2)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the neural network model isn't a significant improvement over the previous model. My hypothesis here is that the data we are providing isn't containing all the important features. Let's now use the data that also has G1 and G2 as features.\n",
    "\n",
    "## AdaBoost model on new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1024 candidates, totalling 5120 fits\n",
      "Best Parameters: {'model__n_estimators': 20, 'model__learning_rate': 0.9500000000000001, 'model__estimator__min_samples_leaf': 5, 'model__estimator__max_depth': 9}\n",
      "Best Score: 0.9595780433159075\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'model__n_estimators': np.arange(4, 128, 4),\n",
    "    'model__learning_rate': np.arange(0.05, 1.0, 0.05),\n",
    "    'model__estimator__max_depth': np.arange(1, 10, 1),\n",
    "    'model__estimator__min_samples_leaf': np.arange(1, 10, 1),\n",
    "}\n",
    "\n",
    "grid_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, n_iter=1024, scoring='accuracy', n_jobs=-1, verbose=1, random_state=2137) \n",
    "\n",
    "bestModel = grid_search.fit(G3_X_with_G1_G2_train, G3_y_with_G1_G2_train).best_estimator_\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "G3_pred = bestModel.predict(G3_X_with_G1_G2_test)\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on G3: 0.8769230769230769\n",
      "Precision on G3: 0.9166666666666666\n",
      "Recall on G3: 0.9339622641509434\n",
      "F1 Score on G3: 0.9252336448598131\n",
      "Confusion Matrix on G3:\n",
      " [[15  9]\n",
      " [ 7 99]]\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.68      0.62      0.65        24\n",
      "        Pass       0.92      0.93      0.93       106\n",
      "\n",
      "    accuracy                           0.88       130\n",
      "   macro avg       0.80      0.78      0.79       130\n",
      "weighted avg       0.87      0.88      0.87       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_G3 = accuracy_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G3 = precision_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G3 = recall_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G3 = f1_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G3 = classification_report(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model hasn't improved much. Let's see the neural network.\n",
    "\n",
    "## Neural network on the new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from ./G3_with_G1_G2/tuner0.json\n",
      "{'units': 96, 'hidden_layers': 4, 'activation': 'relu', 'dropout': 0.2, 'size_factor': 4.0}\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bigpoppe/UJ/PSI/.venv/lib/python3.12/site-packages/keras/src/saving/saving_lib.py:415: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 30 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "from keras_tuner import RandomSearch\n",
    "from keras import models, layers, callbacks\n",
    "\n",
    "def build_model(hp):\n",
    "    model = models.Sequential([\n",
    "        layers.Input((32,)),\n",
    "    ])\n",
    "\n",
    "    units = hp.Int('units', min_value=32, max_value=128, step=32)\n",
    "    current_units = units\n",
    "\n",
    "    for i in range(1, hp.Int('hidden_layers', min_value=2, max_value=6, step=1)):\n",
    "\n",
    "        model.add(layers.Dense(units=current_units, activation=hp.Choice('activation', ['relu', 'sigmoid', 'softmax'])))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(hp.Float('dropout', min_value=0.0, max_value=0.5, step=0.1)))\n",
    "        current_units = int(current_units // hp.Float('size_factor', min_value=1.0, max_value=4.0, step=0.5))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid',))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(monitor='accuracy', patience=8) \n",
    "\n",
    "transformed_G3_X_with_G1_G2_train = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_with_G1_G2_train, G3_y_with_G1_G2_train)\n",
    "transformed_G3_X_with_G1_G2_test = Pipeline(steps=preprocessing_steps).fit_transform(G3_X_with_G1_G2_test, G3_y_with_G1_G2_test)\n",
    "\n",
    "tuner = RandomSearch(hypermodel=build_model, objective='val_accuracy', max_trials=128, seed=2137, project_name='G3_with_G1_G2')\n",
    "tuner.search(transformed_G3_X_with_G1_G2_train, G3_y_with_G1_G2_train, epochs=128, callbacks=[early_stopping], validation_data=(transformed_G3_X_with_G1_G2_test, G3_y_with_G1_G2_test), verbose=1)\n",
    "\n",
    "model = tuner.get_best_models()[0]\n",
    "print(tuner.get_best_hyperparameters()[0].values)\n",
    "\n",
    "G3_pred = model.predict(transformed_G3_X_with_G1_G2_test)\n",
    "G3_pred = np.where(G3_pred >= 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model's metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">3,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">150</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m3,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │         \u001b[38;5;34m2,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │            \u001b[38;5;34m96\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m150\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │            \u001b[38;5;34m24\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m7\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,157</span> (24.05 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,157\u001b[0m (24.05 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,905</span> (23.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,905\u001b[0m (23.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">252</span> (1008.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m252\u001b[0m (1008.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Accuracy on G3: 0.9384615384615385\n",
      "Precision on G3: 0.9537037037037037\n",
      "Recall on G3: 0.9716981132075472\n",
      "F1 Score on G3: 0.9626168224299065\n",
      "Confusion Matrix on G3:\n",
      " [[ 19   5]\n",
      " [  3 103]]\n",
      "Classification Report on G3:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        Fail       0.86      0.79      0.83        24\n",
      "        Pass       0.95      0.97      0.96       106\n",
      "\n",
      "    accuracy                           0.94       130\n",
      "   macro avg       0.91      0.88      0.89       130\n",
      "weighted avg       0.94      0.94      0.94       130\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())\n",
    "\n",
    "accuracy_G3 = accuracy_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Accuracy on G3:\", accuracy_G3)\n",
    "\n",
    "precision_G3 = precision_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Precision on G3:\", precision_G3)\n",
    "\n",
    "recall_G3 = recall_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Recall on G3:\", recall_G3)\n",
    "\n",
    "f1_G3 = f1_score(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"F1 Score on G3:\", f1_G3)\n",
    "\n",
    "conf_matrix_G3 = confusion_matrix(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred)\n",
    "print(\"Confusion Matrix on G3:\\n\", conf_matrix_G3)\n",
    "\n",
    "target_names = ['Fail', 'Pass']\n",
    "classification_report_G3 = classification_report(y_true=G3_y_with_G1_G2_test, y_pred=G3_pred, target_names=target_names)\n",
    "print(\"Classification Report on G3:\\n\", classification_report_G3) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
